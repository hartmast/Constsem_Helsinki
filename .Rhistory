if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
M
cat(readLines(M), sep = "\n")
cat("\nCXXFLAGS+=-flto -Wno-unused-local-typedefs",
file = M, sep = "\n", append = TRUE)
cat("\nCXXFLAGS += -Wno-ignored-attributes -Wno-deprecated-declarations",
file = M, sep = "\n", append = TRUE)
remove.packages("rstan")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
remove.packages("rstan")
Sys.setenv(MAKEFLAGS = "-j4")
install.packages("Rcpp")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 ) # should be 10
library(data.table)
install.packages("koRpus")
install.packages("ggmap", dependencies = T)
iconv("%D9%86", "UTF-8")
iconv("%D9%86", "UTF-8", "UTF-8")
cat("%D9%86")
cat("ن")
"ن"
iconv("ن", "UTF-8", "ANSI")
iconv("ن", "UTF-8", "Latin-1")
iconv("ن", "UTF-8")
Encoding("ن")
"\u%D9%86"
"\u03A7"
"\\u%D9%86"
"\u%D9%86"
7*12
1000/8
setwd("~/Downloads/wiki/wikitrack-vocabulary/code")
pitch = c(233,204,242,130,112,142)
sex = c(rep("female",3),rep("male",3))
my.df = data.frame(sex,pitch)
my.df
lm(pitch~sex, my.df)
xmdl <- lm(pitch~sex, my.df)
summary(xmdl)
plot(xmdl)
plot(my.df)
lattice::dotplot(my.df)
lattice::dotplot(t(my.df))
plot(my.df$sex, my.df$pitch, type="p")
?plot
?dotplot
dotplot(my.df)
dotchart(my.df)
stripchart(my.df)
dotchart(t(my.df))
dotchart(x = pitch, y = sex)
?dotchart
library(ggplot2)
ggplot(my.df, aes(x = sex, y = pich)) + geom_point()
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point()
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth()
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm")
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", formula = y~x)
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", se = FALSE)
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", se = FALSE, data=my.df)
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", se = FALSE)
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", se = TRUE)
lm(my.df)
ggplot(my.df, aes(x = sex, y = pitch)) + geom_point() + geom_smooth(method="lm", formula = pitch~sex, se = TRUE)
ggplot(my.df, aes(x = sex, y = as.numeric(pitch))) + geom_point() + geom_smooth(method="lm",
formula = pitch~sex, se = TRUE)
ggplot(my.df, aes(x = as.numeric(sex), y = as.numeric(pitch))) + geom_point() + geom_smooth(method="lm",
formula = pitch~sex, se = TRUE)
ggplot(my.df, aes(x = sex, y = as.numeric(pitch))) + geom_point() + geom_smooth(method="lm",
formula = pitch~sex, se = TRUE)
ggplot(my.df, aes(x = sex, y = as.numeric(pitch))) + geom_point() + geom_smooth(method="lm",
formula = pitch~as.numeric(sex), se = TRUE)
ggplot(my.df, aes(x = sex, y = as.numeric(pitch))) + geom_point()
# clear workspace
rm(list=ls(all=T))
# install / load packages
sapply(c("dplyr", "reshape2", "ggplot2", "xml2", "XML", "vcd", "cfa", "data.table", "gridExtra", "scales"), function(x)
if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
lapply(list("dplyr", "reshape2", "ggplot2", "xml2", "XML", "vcd", "data.table", "scales"), require, character.only=T)
# set options
options(stringsAsFactors = F)
Sys.setlocale("LC_ALL", "de_DE")
# splitter (unlist + strsplit)
splitter <- function(x, split, ...) {
unlist(strsplit(x, split, ...))
}
# get_last: get last element of a subset in a vector
get_last <- function(df, colname, sbs) {
df[max(which(df[,which(colnames(df)==as.character(colname))] %in% sbs)),]
}
if (Sys.info()['sysname']=="Windows") {
# read list of files
files1 <- paste("..\\Kernkorpus gemergt\\", list.files("..\\Kernkorpus gemergt\\", pattern=".*xml"),
sep="")
files2 <- paste("..\\Erweitertes Korpus gemergt\\", list.files("..\\Erweitertes Korpus gemergt\\", pattern=".*xml"),
sep="")
files3 <- paste("..\\Gesamtkorpus gemergt\\", list.files("..\\Gesamtkorpus gemergt\\", pattern=".*xml"),
sep="")
} else {
# read list of files
files1 <- paste("../Kernkorpus gemergt/", list.files("../Kernkorpus gemergt/", pattern=".*xml"),
sep="")
files2 <- paste("../Erweitertes Korpus gemergt/", list.files("../Erweitertes Korpus gemergt/", pattern=".*xml"),
sep="")
files3 <- paste("../Gesamtkorpus gemergt/", list.files("../Gesamtkorpus gemergt/", pattern=".*xml"),
sep="")
}
files <- c(files1, files2, files3)
for(fl in 1:length(files)) {
# read one file
f <- scan(files[fl], what="character", sep="\n", encoding="UTF-8")
##################
# list of tokens #
##################
# find start and end of text
tx_limits <- grep("TextWithNodes", f)
# plain text
ptx <- f[tx_limits[1]:tx_limits[2]]
ptx2 <- splitter(splitter(splitter(splitter(splitter(ptx, "(?=<Node id=\"..\"/>)", perl=T),
"(?=<Node id=\"...\"/>)", perl=T),
"(?=<Node id=\"....\"/>)", perl=T), "(?=<Node id=\".....\"/>)", perl=T), "(?=<Node id=\"......\"/>)", perl=T)
ptx3 <- grep("^Node id", ptx2, value=T)
# get node ids
nodes <- as.numeric(sapply(1:length(ptx3), function(i) gsub("Node id=\"|\"/>.*", "", ptx3[i])))
# get text
tx <- sapply(1:length(ptx3), function(i) gsub("Node id.*>", "", ptx3[i]))
# in one df
df <- data.frame(NODE=nodes, TEXT=tx)
###################
# add annotations #
###################
# get "original markups" section
om_start <- grep("<AnnotationSet Name=\"Original markups\">", f)
x <- grep("</AnnotationSet", f)
om_end <- min(x[which(x > om_start)])
om <- f[om_start:om_end]
## find lemma, belebtheit and pos ##
# find start and end of each annotations
w_start <- grep("Type=\"w\"", om)
x <- grep("</Annotation>", om)
w_end <- sapply(1:length(w_start), function(i) min(x[which(x>w_start[i])]))
# find start and end tags within annotation
start_nodes <- as.numeric(sapply(1:length(w_start), function(i) gsub(".*StartNode=\"|\" EndNode.*", "", om[w_start[i]])))
end_nodes <- as.numeric(sapply(1:length(w_start), function(i) gsub(".*EndNode=\"|\">", "", om[w_start[i]])))
# combine in df
meta_df <- data.frame(START=start_nodes, END=end_nodes)
# find lemma and pos
meta_df$lemma <- meta_df$pos <- meta_df$belebtheit <- meta_df$id <- NA
# FUNCTION for finding values
get_val <- function(n, val) {
c <- om[w_start[n]:w_end[n]]
if(length(grep(paste("  <Name className=\"java.lang.String\">", val, sep="", collapse=""), c))>0) {
x <- gsub("  <Value className=\"java.lang.String\">|</Value>", "",
c[grep(paste("  <Name className=\"java.lang.String\">", val, sep="", collapse=""), c)+1])
if(length(x)>0) return(x) else return(NA)
} else {
return(NA)
}
}
# get all
for(i in 1:nrow(meta_df)) {
meta_df$lemma[i] <- get_val(i, "lemma")
meta_df$pos[i] <- get_val(i, "pos")
meta_df$belebtheit[i] <- get_val(i, "belebtheit")
meta_df$id[i] <- get_val(i, "id")
# print(i)
}
# add pos and lemma information to df
df$LEMMA <- df$POS <- df$BELEBTHEIT <- df$ID <- NA
for(i in 1:nrow(meta_df)) {
df[which(df$NODE==meta_df$START[i]):which(df$NODE==meta_df$END[i]),]$POS <- meta_df$pos[i]
df[which(df$NODE==meta_df$START[i]):which(df$NODE==meta_df$END[i]),]$LEMMA <- meta_df$lemma[i]
df[which(df$NODE==meta_df$START[i]):which(df$NODE==meta_df$END[i]),]$BELEBTHEIT <- meta_df$belebtheit[i]
df[which(df$NODE==meta_df$START[i]):which(df$NODE==meta_df$END[i]),]$ID <- meta_df$id[i]
print(i)
}
# add start and end of sentence
satz_start <- grep("Annotation Id.*Type=\"satz\"", om)
x <- grep("</Annotation>", om)
satz_end <- sapply(1:length(satz_start), function(i) min(x[which(x>satz_start[i])]))
# find start and end tag of sentences
start_nodes <- as.numeric(sapply(1:length(satz_start), function(i) gsub(".*StartNode=\"|\" EndNode.*", "", om[satz_start[i]])))
end_nodes <- as.numeric(sapply(1:length(satz_start), function(i) gsub(".*EndNode=\"|\">", "", om[satz_start[i]])))
# add to df
df$SATZ <- NA
df[which(df$NODE %in% start_nodes),]$SATZ <- "SATZ_START"
df[which(df$NODE %in% end_nodes),]$SATZ <- "SATZ_END"
# add w_func
func_start <- grep("Annotation Id.*Type=\"w_func\"", om)
x <- grep("</Annotation>", om)
func_end <- sapply(1:length(func_start), function(i) min(x[which(x>func_start[i])]))
# find start and end tags of w_func
start_nodes <- as.numeric(sapply(1:length(func_start), function(i) gsub(".*StartNode=\"|\" EndNode.*", "", om[func_start[i]])))
end_nodes <- as.numeric(sapply(1:length(func_start), function(i) gsub(".*EndNode=\"|\">", "", om[func_start[i]])))
# FUNCTION for finding values
get_val <- function(n, val) {
c <- om[func_start[n]:func_end[n]]
if(length(grep(paste("  <Name className=\"java.lang.String\">", val, sep="", collapse=""), c))>0) {
x <- gsub("  <Value className=\"java.lang.String\">|</Value>", "",
c[grep(paste("  <Name className=\"java.lang.String\">", val, sep="", collapse=""), c)+1])
if(length(x)>0) return(x) else return(NA)
} else {
return(NA)
}
}
# get values
meta_df2 <- data.frame(start=start_nodes, end=end_nodes)
meta_df2$sr <- meta_df2$func_id <- meta_df2$embedded <- meta_df2$synfunc <- NA
for(i in 1:nrow(meta_df2)) {
meta_df2$sr[i] <- get_val(i, "sr")
meta_df2$func_id[i] <- get_val(i, "func_id")
meta_df2$embedded[i] <- get_val(i, "embedded")
meta_df2$synfunc[i] <- get_val(i, "synfunc")
# print(i)
}
# single out attributes
attr_df2 <- filter(meta_df2, embedded %in% c("true", "true-attr"))
meta_df2 <- filter(meta_df2, embedded=="false")
# insert to df #
# add column for random ids:
df$func <- NA
# generate random ids
randomz <- sample(1000000:9999999, nrow(meta_df2))
# add random ids
for(i in 1:nrow(meta_df2)) {
df[(which(df$NODE==meta_df2$start[i])):(which(df$NODE==meta_df2$end[i])),]$func <-
paste(gsub(" .*", "", files[fl]), randomz, sep="")[i]
}
# fill table
df$synfunc <- df$embedded <- df$func_id <- df$sr <- NA
for(i in 1:nrow(meta_df2)) {
df[which(df$NODE==meta_df2$start[i]):which(df$NODE==meta_df2$end[i]),]$synfunc <- meta_df2$synfunc[i]
df[which(df$NODE==meta_df2$start[i]):which(df$NODE==meta_df2$end[i]),]$embedded <- meta_df2$embedded[i]
df[which(df$NODE==meta_df2$start[i]):which(df$NODE==meta_df2$end[i]),]$func_id <- meta_df2$func_id[i]
df[which(df$NODE==meta_df2$start[i]):which(df$NODE==meta_df2$end[i]),]$sr <- meta_df2$sr[i]
# print(i)
}
# plus embedded values
df$synfunc2 <- df$embedded2 <- df$func_id2 <- df$sr2 <- df$func2 <- NA
# generate random ids
randomz <- sample(1000000:9999999, nrow(attr_df2))
# add random ids
if(nrow(attr_df2)>0) {
for(i in 1:nrow(attr_df2)) {
df[(which(df$NODE==attr_df2$start[i])):(which(df$NODE==attr_df2$end[i])),]$func2 <-
paste(gsub(" .*", "", files[fl]), randomz, sep="")[i]
}
}
if(nrow(attr_df2)>0) {
for(i in 1:nrow(attr_df2)) {
df[which(df$NODE==attr_df2$start[i]):which(df$NODE==attr_df2$end[i]),]$synfunc2 <- attr_df2$synfunc[i]
df[which(df$NODE==attr_df2$start[i]):which(df$NODE==attr_df2$end[i]),]$embedded2 <- attr_df2$embedded[i]
df[which(df$NODE==attr_df2$start[i]):which(df$NODE==attr_df2$end[i]),]$func_id2<- attr_df2$func_id[i]
df[which(df$NODE==attr_df2$start[i]):which(df$NODE==attr_df2$end[i]),]$sr2 <- attr_df2$sr[i]
# print(i)
}
}
if(fl==1) {
kwic <- mutate(df, FILE=files[fl])
} else {
kwic <- rbind(kwic, mutate(df, FILE=files[fl]))
}
print(fl)
}
getwd()
data(cars)
head(cars)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(zoo)
library(tidytext)
#read whatever is needed from here
setwd("~/Downloads/wiki/wikitrack-vocabulary/code")
all_prop_bycat_limited <- fread("../data/local/multiling/all_prop_bycat_limited.tsv")
all_prop_bycat_nolimit <- fread("../data/local/multiling/all_prop_bycat_nolimit.tsv")
all_prop_nocat_limited <- fread("../data/local/multiling/all_prop_nocat_limited.tsv")
all_prop_nocat_nolimit <- fread("../data/local/multiling/all_prop_nocat_nolimit.tsv")
de_tokens_nocat_limited <- fread("../data/local/multiling/boolean_alldata_de.tsv")
onsets <- fread("../data/local/multiling/onsets2_species_all.tsv",sep="\t")
headers_results <- fread("../data/local/multiling/headers_results_species_all.tsv",sep="\t")
headers_results_bycat <- fread("../data/local/multiling/headers_results_bycat_species_all.tsv",sep="\t")
headers_results_ft <- fread("../data/local/multiling/headers_results_ft_species_all.tsv",sep="\t")
headers_results_bycat_ft <- fread("../data/local/multiling/headers_results_bycat_ft_species_all.tsv",sep="\t")
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(zoo)
library(tidytext)
list.files
list.files()
?I
list.files("../")
test <- concordances::getCWB("more_less_ADJ_control.txt")
test
test
grep("\\.", tag0002)
grep("\\.", test$tag0002)
grep("\\.", test$tag0002, value = T)
test[grep("\\.", test$tag0002),]
test[grep("\\.", test$tag0002)[],]
test[grep("\\.", test$tag0002)[1],]
test[grep("\\.", test$tag0002)[2],]
test[grep("\\.", test$tag0002)[2],]$tag0002
test[grep("\\.", test$tag0002)[2],c(Keyword, tag0002)]
test[grep("\\.", test$tag0002)[2],c(Key, tag0002)]
test[grep("\\.", test$tag0002)[3],c(Key, tag0002)]
test[grep("\\.", test$tag0002)[3],c(Left, Key, Right, tag0002)]
test[grep("\\.", test$tag0002)[3],c(No, Left, Key, Right, tag0002)]
test <- concordances::getCWB("more_less_aj0.txt")
test
test
str(test)
gsub("_&_&", "", test$Key[1])
gsub("&_&_.*", "", test$Key[1])
gsub(".*&_&_", "", test$Key[1])
gsub("_&_&.*", "", test$Key[1])
test$Key[1]
test$Key[2]
list.files
list.files()
test[1,]
test <- concordances::getCWB("more_less_aj0.txt")
test
test
grep("ADJ", test$tag0002, invert = T)
grep("ADJ", test$tag0002, invert = T, value = T)
liibrary(concordances)
library(concordances)
t <- getCWB("more_less_aj0.txt")
aj0 <- getCWB("more_less_aj0.txt")
aj0
aj0
setnames(aj0, "tag0002", "Lemma")
aj0[, Lemma_Key := gsub(".* ", "", Lemma)]
aj0
ajc <- getCWB("ajc.txt")
ajc <- getCWB("ajc.txt")
ajc
ajc
grep("ADJ," ajc$tag0002, value=T)
grep("ADJ," ajc$tag0002, value=T, invert=T)
grep("ADJ", ajc$tag0002, value=T, invert=T)
ajc
unique(ajc$Key_with_anno)
ajc
setnames(ajc, "tag0002", "Lemma")
library(childesdb)
library(childes-db)
install.packages("childesdb")
library(childesr)
thomas <- d_transcripts <- get_transcripts(collection = NULL,
corpus = NULL,
child = "Thomas")
thomas
thomas2 <- get_participants(child = "Thomas")
thomas2 <- get_participants(role = "Target_Child")
thomas2$name
thomas2[name=="Thomas"]
thomas2[name=="Thomas",]
thomas2[thomas2$name=="Thomas",]
?get_participants
thomas2[thomas2$name=="THOMAS",]
thomas2[thomas2$name=="THOMAS",]$name
library(concordances)
aj0
ajc
write.table(aj0, "aj0.csv", sep="\t", row.names=F, quote=F, fileEncoding = "UTF-8")
write.table(ajc, "ajc.csv", sep="\t", row.names=F, quote=F, fileEncoding = "UTF-8")
library(rJava)
install.packages("rJava")
library(rJava)
library(xlsx)
?system
if(!is.element("devtools", installed.packages())) {
install.packages("devtools")
}
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
library(concordances)
getwd()
!require("pkgKitten")
!require(pkgKitten)
300 / 4
400 / 4
75*3
220 / 3
library(collostructions)
?collex
(-10)^2
(-10)^2  / 2
(-18)^2 / 2
(-18)^2
(0-18.42)^2
(0-18.42)^2/0
5*4
20*9
5*4
20*3
287+138
248.5+106.5
29.9+19.9
29.9+19.9+257.6
29*2
52+151
154+270
514/4
128+138
172.5*12
19.53*3
58.59+19.55
x <- readLines("https://www.navigium.de/latein-woerterbuch.php?form=dicens&wb=gross&phr=true&mh=true")
x
grep("Ergebnis der Suche", x, value = T)
x <- readLines("https://www.navigium.de/latein-woerterbuch.php?form=facies&wb=gross&phr=true&mh=true")
x
grep("Ergebnis der Suche", x, value = T)
y <-
grep("Ergebnis der Suche", x, value = T)
grep("Fut", y)
?readLines
?scan
scan("/Volumes/My Passport/DECOW16AX/decow16a.doc.csv", what = "character", nmax = 100)
scan("/Volumes/My Passport/DECOW16AX/decow16a.doc.csv", what = "character", nmax = 200)
scan("/Volumes/My Passport/DECOW16AX/decow16a.doc.csv", what = "character", nmax = 200, sep="\n")
scan("/Volumes/My Passport/DECOW16AX/decow16a.doc.csv", what = "character", nmax = 200)
update.packages(ask = FALSE, repos = 'https://cran.rstudio.org')
install.packages('knitr', repos = c('https://xran.yihui.name', 'https://cran.rstudio.org'))
devtools::install_github("ramnathv/slidify")
install.packages('tidyverse')
install.packages('car')
install.packages('MASS')
install.packages('pscl')
install.packages('effsize')
install.packages('effects')
install.packages('broom')
install.packages('dotwhisker')
install.packages('lme4')
install.packages('afex')
install.packages('brms')
install.packages('MuMIn')
?runif
library(tidyverse)
165+40
install.packages("gutenbergr")
library(gutenbergr)
sherlock_raw <- gutenberg_download(1661)
barplot(c(1,3,4))
grid()
barplot(c(1,3,4))
grid()
barplot(c(1,3,4), add = T)
library(concordances)
getWACKY("/Users/stefanhartmann/Downloads/dewac_concordance2.xml")
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance.txt")
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance.txt") %>% head
library(tidyverse)
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance.txt") %>% head
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance.txt", tags = F) %>% head
getCWB("/Users/stefanhartmann/Downloads/dewac_conordance3.txt")
getCWB("/Users/stefanhartmann/Downloads/dewac_conordance3.txt") %>% head
getCWB("/Users/stefanhartmann/Downloads/dewac_conordance4.txt") %>% head
getCWB("/Users/stefanhartmann/Downloads/dewac_concordance4.txt") %>% head
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance5.xml")
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance5.xml") %>% head
getNSE("/Users/stefanhartmann/Downloads/dewac_concordance6.xml") %>% head
?getNSE
getNSE
getWACKY("/Users/stefanhartmann/Downloads/dewac_concordance4.txt") %>% head
?getWACKY
getWACKY("/Users/stefanhartmann/Downloads/dewac_concordance6.xml") %>% head
setwd("/Users/stefanhartmann/Dropbox/Privat/Constsem_Helsinki")
library(rmarkdown)
library(slidify)
slidify::author()
slidify::author(deckdir = ".")
getwd()
readLines("../Projekte/werdenFutur/TenseExperiment/Exp/TempSurvey copy.html")
# Chunk 1
library(inserttable)
warnings()
inserttable:::insert_table()
?sliderInput
# Chunk 1
table1 <- tibble::tribble(
~'', ~near, ~distant, ~indefinite,
"futurate present", "123",    "102",        "97",
"werden + Infinitive",  "60",     "96",        "94"
)
require(knitr)
require(kableExtra)
kable_styling(
kable(table1, digits = 3, row.names = FALSE, align = "c",
caption = NULL, format = "html"),
bootstrap_options = c("striped", "hover", "condensed"),
position = "center", full_width = FALSE)
library(inserttable)
inserttable:::insert_table()
inserttable:::insert_table()
inserttable:::insert_table()
inserttable:::insert_table()
library(slidify)
